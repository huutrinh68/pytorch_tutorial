{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southern-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "irish-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, inp, out, kernel, stride, padding, bias, act):\n",
    "        super().__init__()\n",
    "        if act:\n",
    "            self.conv_block = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(inp, out, kernel, stride, padding, bias),\n",
    "                torch.nn.BatchNorm2d(out),\n",
    "                torch.nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.conv_block = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(inp, out, kernel, stride, padding, bias),\n",
    "                torch.nn.BatchNorm2d(out)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "literary-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeConvBlock(torch.nn.Module):\n",
    "    def __init__(self, inp, out, kernel, stride, padding):\n",
    "        super().__init__()\n",
    "        self.conv_transpose = torch.nn.ConvTranspose2d(inp, out, kernel, stride, padding)\n",
    "        self.batchnorm = torch.nn.BatchNorm2d(out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, out):\n",
    "        conv_transpose = self.conv_transpose(x, output_size=out)\n",
    "        batchnorm = self.batchnorm(conv_transpose)\n",
    "        return self.relu(batchnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enabling-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \"\"\"Downsampling image size to 2 times\"\"\"\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            ConvBlock(inp=inp, out=out, kernel=3, stride=2, padding=1, bias=True, act=True),\n",
    "            ConvBlock(inp=out, out=out, kernel=3, stride=1, padding=1, bias=True, act=True)\n",
    "        )\n",
    "        \n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            ConvBlock(inp=out, out=out, kernel=3, stride=1, padding=1, bias=True, act=True),\n",
    "            ConvBlock(inp=out, out=out, kernel=3, stride=1, padding=1, bias=True, act=True)\n",
    "        )\n",
    "        \n",
    "        self.residue = ConvBlock(inp=inp, out=out, kernel=3, stride=2, padding=1, bias=True, act=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x) # downsampling by 2\n",
    "        residue = self.residue(x) # downsampling by 2\n",
    "        block2 = self.block2(block1 + residue) # same size\n",
    "        return block1 + block2 # downsampling by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "retained-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeCoder(torch.nn.Module):\n",
    "    \"\"\"Upsampling image size to 2 times\"\"\"\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = ConvBlock(inp, inp//4, kernel=1, stride=1, padding=0, bias=True, act=True)\n",
    "        self.de_conv_block1 = DeConvBlock(inp=inp//4, out=inp//4, kernel=3, stride=2, padding=1)\n",
    "        self.conv_block2 = ConvBlock(inp//4, out, kernel=1, stride=1, padding=0, bias=True, act=True)\n",
    "        \n",
    "    def forward(self, x, output_size):\n",
    "        conv_block1 = self.conv_block1(x) # same size\n",
    "        de_conv_block1 = self.de_conv_block1(conv_block1, out=output_size) # upsampling by 2\n",
    "        conv_block2 = self.conv_block2(de_conv_block1) # same size\n",
    "        return conv_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "another-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.init_conv = ConvBlock(inp=3, out=64, kernel=7, stride=2, padding=3, bias=True, act=True)\n",
    "        self.init_maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.encoder1 = Encoder(inp=64, out=64)\n",
    "        self.encoder2 = Encoder(inp=64, out=128)\n",
    "        self.encoder3 = Encoder(inp=128, out=256)\n",
    "        self.encoder4 = Encoder(inp=256, out=512)\n",
    "        \n",
    "        self.decoder4 = DeCoder(inp=512, out=256)\n",
    "        self.decoder3 = DeCoder(inp=256, out=128)\n",
    "        self.decoder2 = DeCoder(inp=128, out=64)\n",
    "        self.decoder1 = DeCoder(inp=64, out=64)\n",
    "        \n",
    "        self.final_deconv1 = DeConvBlock(inp=64, out=32, kernel=3, stride=2, padding=1)\n",
    "        self.final_conv = ConvBlock(inp=32, out=32, kernel=3, stride=1, padding=1, bias=True, act=True)\n",
    "        self.final_deconv2 = DeConvBlock(inp=32, out=2, kernel=2, stride=2, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        init_conv = self.init_conv(x) # downsampling by 2\n",
    "        init_maxpool = self.init_maxpool(init_conv) # downsampling by 2\n",
    "        \n",
    "        e1 = self.encoder1(init_maxpool) # downsampling by 2\n",
    "        e2 = self.encoder2(e1) # downsampling by 2\n",
    "        e3 = self.encoder3(e2) # downsampling by 2\n",
    "        e4 = self.encoder4(e3) # downsampling by 2\n",
    "\n",
    "        d4 = self.decoder4(e4, e3.size()) + e3 # upsampling by 2\n",
    "        d3 = self.decoder3(d4, e2.size()) + e2 # upsampling by 2\n",
    "        d2 = self.decoder2(d3, e1.size()) + e1 # upsampling by 2\n",
    "        d1 = self.decoder1(d2, init_maxpool.size()) # upsampling by 2\n",
    "        \n",
    "        final_deconv1 = self.final_deconv1(d1, init_conv.size()) # upsampling by 2\n",
    "        final_conv = self.final_conv(final_deconv1) # same size\n",
    "        final_deconv2 = self.final_deconv2(final_conv, x.size()) # upsampling by 2\n",
    "        \n",
    "        return final_deconv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "institutional-specification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 256, 256])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinkNet()\n",
    "x = torch.Tensor(1, 3, 256, 256)\n",
    "y = model(x)\n",
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
